{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TD 11-12**\n",
    "\n",
    "### Collecte, Traitement, et Analyse de donn√©es de r√©seaux sociaux\n",
    "\n",
    "LEFEVRE Laura et LE CORRE Camille - LDD BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des modules\n",
    "import json\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import textblob_fr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Module a installer\n",
    "    #!pip install textblob\n",
    "    #!pip install textblob-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFile(fileName):\n",
    "    with open(fileName, encoding='utf8') as json_data:\n",
    "        data_dict = json.load(json_data)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1421599163561742339',\n",
       " 'public_metrics': {'retweet_count': 0,\n",
       "  'reply_count': 1,\n",
       "  'like_count': 1,\n",
       "  'quote_count': 0},\n",
       " 'id': '1421599163561742339',\n",
       " 'conversation_id': '1421599163561742339',\n",
       " 'context_annotations': [{'domain': {'id': '6', 'name': 'Sports Event'},\n",
       "   'entity': {'id': '1103026158382141440',\n",
       "    'name': 'Tokyo 2020 Summer Olympics',\n",
       "    'description': 'Tokyo 2020 Summer Olympics '}}],\n",
       " 'author_id': '1339914264522461187',\n",
       " 'text': 'Ah oui le sommeil l√† sera compliqu√©. #CIV  est √©limin√© des JO , Ahi on peut faire √ßa ?',\n",
       " 'geo': {'place_id': '00b8943291443c8c'},\n",
       " 'lang': 'fr',\n",
       " 'created_at': '2021-07-31T22:30:27.000Z',\n",
       " 'entities': {'hashtags': [{'start': 37, 'end': 41, 'tag': 'CIV'}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = openFile(\"versailles_tweets_100.json\")\n",
    "dic[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goumin des √©l√©phants joueurs la m√™me fatigue m√™me üò´ #twitter225'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%¬∞\\.]*\", \"\", text)\n",
    "    text = re.sub(r\"[\\,\\!\\?\\%\\(\\)\\/\\\"\\&\\+\\#\\$\\¬£\\%\\:\\@\\-]\", \"\", text)\n",
    "    text = re.sub(r\"[\\√©\\√®\\√™]\", \"e\", text)\n",
    "    text = re.sub(r\"[\\√π]\", \"u\", text)\n",
    "    text = re.sub(r\"[\\√†]\", \"a\", text)\n",
    "    text = re.sub(r\"[\\√Æ\\√Ø]\", \"i\", text)\n",
    "    text = remove_emojis(text)\n",
    "    text = re.sub(r\"( )+\", \" \", text)\n",
    "    text = re.sub(r\"( )*$\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goumin des elephants joueurs la meme fatigue meme'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(dic[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZoneAtterrissage(tweet):\n",
    "    tweet_clean = clean_text(tweet['text'])\n",
    "    tweet['text'] = tweet_clean\n",
    "\n",
    "    with open(\"zone_atterrissage1.json\", \"a\") as filout:\n",
    "        taille = os.path.getsize(\"zone_atterrissage1.json\")\n",
    "        print(taille)\n",
    "        if taille == 0:\n",
    "            json.dump([tweet], filout)\n",
    "        else :\n",
    "            pass\n",
    "    \n",
    "    with open(\"zone_atterrissage1.json\", 'w', encoding='utf8') as filout:\n",
    "        taille = os.path.getsize(\"zone_atterrissage1.json\")\n",
    "        if taille > 0:\n",
    "            data_dict = json.load(filout)\n",
    "            data_dict.append(tweet)\n",
    "            json.dump(data_dict, filout)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic = open('zone_atterrissage.json', 'r')\n",
    "fic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement(liste_tweet):\n",
    "    \n",
    "    for elt in liste_tweet:\n",
    "        ZoneAtterrissage(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "traitement(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListHashtags(tweet):\n",
    "    ''' Fonction qui renvoie la liste de hashtags d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_hashtags = []\n",
    "\n",
    "    if \"hashtags\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un hashtag\n",
    "        for h in range(len(tweet[\"entities\"][\"hashtags\"])):            # on parcourt la liste des hashtags\n",
    "            list_hashtags.append(tweet[\"entities\"][\"hashtags\"][h][\"tag\"])   \n",
    "\n",
    "    return list_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListMentionedUsers(tweet):\n",
    "    ''' Fonction qui renvoie la liste des utilisateurs mentionn√©s dans un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_mentioned_users = []\n",
    "\n",
    "    if \"mentions\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un utilisateur mentionn√©\n",
    "        for m in range(len(tweet[\"entities\"][\"mentions\"])):            # on parcourt la liste des utilisateurs mentionn√©s\n",
    "            list_mentioned_users.append(tweet[\"entities\"][\"mentions\"][m][\"username\"])\n",
    "\n",
    "    return list_mentioned_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topic(tweet):\n",
    "    ''' Fonction qui d√©termine le topic d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feeling(tweet):\n",
    "    ''' Fonction qui d√©termine le sentiment d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZoneEntrepot(list):\n",
    "    '''Fonction qui prend en entr√©e la liste des dictionnaires correspondant aux tweets\n",
    "    issus du fichier .json et qui cr√©er un DataFrame contenant uniquement les informations utiles'''\n",
    "\n",
    "    # Cr√©ation d'un DataFrame (chaque ligne va correspondre √† un tweet)\n",
    "    zone_entrepot = pd.DataFrame(columns = ['author_id', 'text', 'hashtags', 'mentioned_users', 'topics', 'feelings'])\n",
    "\n",
    "    for k in range(len(list)-1):        # on travaille sur un tweet √† la fois\n",
    "        # Cr√©ation d'une liste qui va contenir toutes les informations utiles de ce tweet\n",
    "        tweet = []\n",
    "        # Ajout √† cette liste des informations r√©cup√©r√©es de la zone d'atterissage\n",
    "        tweet.append(list[k].get(\"author_id\"))              # auteur du tweet    \n",
    "        tweet.append(list[k].get(\"text\"))                   # texte du tweet\n",
    "        tweet.append(ListHashtags(list[k]))                 # liste des hashtags\n",
    "        tweet.append(ListMentionedUsers(list[k]))           # liste des utilisateurs mentionn√©s\n",
    "        tweet.append(Topic(list[k]))                       # topic\n",
    "        tweet.append(Feeling(list[k]))                     # sentiment\n",
    "        \n",
    "        # Ajout de la ligne correspondant √† ce tweet √† notre DataFrame\n",
    "        zone_entrepot.loc[k+1] = tweet\n",
    "\n",
    "    return zone_entrepot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fffb65c47ed2133fd664d3a0067ed67d5fc57a12224b3043734fa1ac4f51c235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
