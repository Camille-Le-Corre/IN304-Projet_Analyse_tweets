{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TD 11 et 12 - Collecte, Traitement, et Analyse de donn√©es de r√©seaux sociaux**\n",
    "\n",
    "##### *LEFEVRE Laura et LE CORRE Camille - LDD BI*\n",
    "\n",
    "\n",
    "### I- Traitement des donn√©es\n",
    "\n",
    "Dans cette premi√®re partie, nous r√©cup√©rons les donn√©es, nous les nettoyons et les organisons, pour obtenir un DataFrame contenant les donn√©es qui nous int√©ressent pour la suite du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des diff√©rents modules utilis√©s dans notre programme\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random as rd\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "# Modules a installer\n",
    "    #!pip install textblob\n",
    "    #!pip install textblob-fr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, on d√©finit une fonction qui va nous permettre de r√©cup√©rer dans une variable, la liste des dictionnaires repr√©sentant les diff√©rents tweets contenu dans le fichier json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFile(fileName):\n",
    "    '''Fonction qui permet de lire et de recuperer un fichier json dans une variable data_dict'''\n",
    "    \n",
    "    with open(fileName, encoding='utf8') as json_data:\n",
    "        data_dict = json.load(json_data)\n",
    "        \n",
    "        return data_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, la commande suivante permet de r√©cup√©rer dans la varible dic, la liste des tweets du fichier \"versailles_tweets_100.json\". On obtient une liste de dictionnaire et dic[0] nous permet de visualiser le premier tweet. On peut voir qu'il poss√®de plusieurs √©l√©ments qui ne vont pas nous servir. Nous allons donc pouvoir nettoyer chacun des tweets, en gardant les informations essentiels (author_id, text, hastags...). De plus, on va pouvoir nettoyer le texte du tweet en supprimant tous les caract√®res sp√©ciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1421616335700824064',\n",
       " 'public_metrics': {'retweet_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 1,\n",
       "  'quote_count': 0},\n",
       " 'id': '1421616335700824064',\n",
       " 'conversation_id': '1421616335700824064',\n",
       " 'author_id': '1339914264522461187',\n",
       " 'text': 'Goumin des √©l√©phants joueurs la m√™me fatigue m√™me üò´ #twitter225',\n",
       " 'geo': {'place_id': '00b8943291443c8c'},\n",
       " 'lang': 'fr',\n",
       " 'created_at': '2021-07-31T23:38:41.000Z',\n",
       " 'entities': {'hashtags': [{'start': 52, 'end': 63, 'tag': 'twitter225'}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = openFile(\"versailles_tweets_100.json\")\n",
    "dic[0]\n",
    "\n",
    "# changer nom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On code les fonctions permettant le nettoyage :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Supprimer les emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeEmojis(data):\n",
    "    '''Fonction qui permet de supprimer les emojis du text d'un tweet \n",
    "    (source : https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python)'''\n",
    "    \n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Supprimer tous les caract√®res sp√©ciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    '''Fonction qui permet de nettoyer le texte d'un tweet a l'aide de regex'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = removeEmojis(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', \"\", text)                            # suppression des URL\n",
    "    text = re.sub(r'@([A-Za-z0-9_]+)', \"\", text)                                # suppresion des mentions\n",
    "    text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%¬∞\\.]*\", \"\", text)\n",
    "    text = re.sub(r\"#([A-Za-z0-9_]+)\", \"\", text)                                # suppresion des hashtags\n",
    "    text = re.sub(r\"[\\,\\!\\?\\%\\(\\)\\/\\\"\\&\\+\\#\\$\\¬£\\%\\:\\.\\@\\-\\n]\", \"\", text)\n",
    "    text = re.sub(r\"[\\√©\\√®\\√™]\", \"e\", text)\n",
    "    text = re.sub(r\"[\\√π]\", \"u\", text)\n",
    "    text = re.sub(r\"[\\√†]\", \"a\", text)\n",
    "    text = re.sub(r\"[\\√Æ\\√Ø]\", \"i\", text)\n",
    "    text = re.sub(r\"( )+\", \" \", text)\n",
    "    text = re.sub(r\"( )*$\", \"\", text)\n",
    "    text = re.sub(r\"^( )\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut maintenant cr√©er la zone d'atterrissage des tweets. \n",
    "On cr√©er donc une fonction qui va nous permettre d'ajouter les tweets dans un autre fichier (zone_atterrissage.json), semblable √† l'initial, mais avec les textes des tweets nettoy√©s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoneAtterrissage(tweet):\n",
    "    '''Fonction qui permet de creer la zone d'atterrisage des tweets. Elle ajoute dans un fichier zone d'atterrissage, un tweet en le nettoyant.'''\n",
    "    \n",
    "    # Nettoie le texte du tweet et remplace le texte initiale par le texte nettoye\n",
    "    tweet_clean = cleanText(tweet['text'])\n",
    "    tweet['text'] = tweet_clean\n",
    "    \n",
    "    # Si le fichier de la zone d'atterrissage n'existe pas, on le creer et on y ajoute le tweet\n",
    "    if os.path.exists(\"zone_atterrissage.json\") == False:\n",
    "        with open(\"zone_atterrissage.json\", \"w\") as fil:\n",
    "            json.dump([tweet], fil)\n",
    "    \n",
    "    # Sinon, on recupere les tweets deja presents, et on y ajoute celui en cours de traitement\n",
    "    else :\n",
    "        li_tweet = openFile(\"zone_atterrissage.json\")\n",
    "        with open(\"zone_atterrissage.json\", 'w') as filout :\n",
    "            li_tweet.append(tweet)\n",
    "            json.dump(li_tweet, filout)\n",
    "            \n",
    "    return\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut √† pr√©sent une fonction qui va nous permettre de traiter les tweets que l'on a √† disposition. On va donc envoyer chaque tweet dans la zone d'atterrissage, l'un apr√®s l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_nettoyage(liste_tweet:list):\n",
    "    '''Cette fonction permet de traiter tous les tweets et de les envoyer dans la zone d'atterrissage'''\n",
    "\n",
    "    for elt in liste_tweet:\n",
    "        zoneAtterrissage(elt)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On execute cette m√©thode en passant en param√®tre le fichier json contenant les tweets. Apr√®s l'ex√©cution on obtient un nouveau fichier json avec les tweets nettoy√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 17\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m traitement_nettoyage(dic)\n",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 17\u001b[0m in \u001b[0;36mtraitement_nettoyage\u001b[1;34m(liste_tweet)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m'''Cette fonction permet de traiter tous les tweets et de les envoyer dans la zone d'atterrissage'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m liste_tweet:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     zoneAtterrissage(elt)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 17\u001b[0m in \u001b[0;36mzoneAtterrissage\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         json\u001b[39m.\u001b[39mdump([tweet], fil)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Sinon, on recupere les tweets deja presents, et on y ajoute celui en cours de traitement\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     li_tweet \u001b[39m=\u001b[39m openFile(\u001b[39m\"\u001b[39;49m\u001b[39mzone_atterrissage.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mzone_atterrissage.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m filout :\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         li_tweet\u001b[39m.\u001b[39mappend(tweet)\n",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 17\u001b[0m in \u001b[0;36mopenFile\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m'''Fonction qui permet de lire et de recuperer un fichier json dans une variable data_dict'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fileName, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m json_data:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     data_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(json_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data_dict\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "traitement_nettoyage(dic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pr√©sent, tous les tweets sont stock√©s dans un nouveau fichier (zone_atterrissage.json). Ils sont nettoy√©s et on va pouvoir cr√©er une zone d'entrepot, sous forme de DataFrame. On va y stocker tous les tweets avec seulement les informations dont on a besoin.\n",
    "On va donc cr√©er un certain nombre de fonctions qui vont nous permettre de r√©cup√©rer ces informations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Une fonction nous permettant d'extraire le texte d'un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textExtract(tweet):\n",
    "    '''Fonction qui retourne le text d'un tweet'''\n",
    "\n",
    "    # On recupere le texte\n",
    "    text = tweet.get(\"text\")\n",
    "\n",
    "    # S'il n'y as pas de text (exemple : c'etait une mention), on retourne None\n",
    "    if text == '':\n",
    "        return\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Une fonction nous permettant d'extraire les hashtags d'un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listHashtags(tweet):\n",
    "    ''' Fonction qui renvoie la liste de hashtags d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_hashtags = []\n",
    "    if \"entities\" in tweet:\n",
    "        if \"hashtags\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un hashtag\n",
    "            for h in range(len(tweet[\"entities\"][\"hashtags\"])):            # on parcourt la liste des hashtags\n",
    "                list_hashtags.append(tweet[\"entities\"][\"hashtags\"][h][\"tag\"])   \n",
    "            \n",
    "            return list_hashtags\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Une fonction nous permettant de r√©cup√©rer les utilisateurs mentionn√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listMentionedUsers(tweet):\n",
    "    ''' Fonction qui renvoie la liste des utilisateurs mentionn√©s dans un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_mentioned_users = []\n",
    "    \n",
    "    if \"entities\" in tweet:\n",
    "        if \"mentions\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un utilisateur mentionn√©\n",
    "            for m in range(len(tweet[\"entities\"][\"mentions\"])):            # on parcourt la liste des utilisateurs mentionn√©s\n",
    "                list_mentioned_users.append(tweet[\"entities\"][\"mentions\"][m][\"username\"])\n",
    "            \n",
    "            return list_mentioned_users\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Une fonction nous permettant d'attribuer un topic √† un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic(tweet):\n",
    "    ''' Fonction qui attribue un topic √† un tweet de fa√ßon al√©atoire.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    \n",
    "    topics = ['sport', 'politic', 'environment', 'TV', 'animal', 'nature', 'celebrity',\n",
    "                                'travel', 'singing', 'love', 'fun', 'history', 'culture']\n",
    "    \n",
    "    if tweet.get('text') != '':             # si le tweet contient un texte\n",
    "        return rd.choice(topics)            # on va lui attribuer un topic\n",
    "    \n",
    "    return                                  # sinon, aucun topic n'est attribu√© "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Une fonction nous permettant d'attribuer un sentiment au tweet (en fonction du texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ il faut trouver le param√®tre pour l'adapter en fran√ßais ou toutes les langues\n",
    "\n",
    "def feeling(tweet):\n",
    "    ''' Fonction qui d√©termine le sentiment d'un tweet (positif, n√©gatif ou neutre).\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    \n",
    "    feeling = TextBlob(tweet.get(\"text\")).sentiment\n",
    "    \n",
    "    if feeling[0] < 0:\n",
    "        return \"negative\"\n",
    "    elif feeling[0] == 0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s avoir d√©clar√© toutes ces fonctions, on peut cr√©er la fonction zoneEntrepot pour cr√©er un DataFrame contenant les tweets avec les informations des fonctions pr√©c√©dentes. Chaque tweet va correspondre √† une ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoneEntrepot(list):\n",
    "    '''Fonction qui prend en entr√©e la liste des dictionnaires correspondant\n",
    "    aux tweets issus du fichier zone_atterrissage.json et qui cr√©er un DataFrame\n",
    "    contenant uniquement les informations qui nous int√©ressent'''\n",
    "\n",
    "    # Cr√©ation d'un DataFrame\n",
    "    zone_entrepot = pd.DataFrame(columns = ['author_id', 'text', 'hashtags', 'mentioned_users', 'topics', 'feelings'])\n",
    "\n",
    "    for k in range(len(list)):        # on travaille sur un tweet √† la fois\n",
    "        # Cr√©ation d'une liste qui va contenir toutes les informations utiles de ce tweet\n",
    "        tweet = []\n",
    "        \n",
    "        # Ajout √† cette liste des informations r√©cup√©r√©es de la zone d'atterissage\n",
    "        tweet.extend([list[k].get(\"author_id\"), textExtract(list[k]), listHashtags(list[k]), listMentionedUsers(list[k]),topic(list[k]), feeling(list[k])])  \n",
    "        \n",
    "        # Ajout de la ligne correspondant au tweet √† notre DataFrame\n",
    "        zone_entrepot.loc[k+1] = tweet\n",
    "\n",
    "    return zone_entrepot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_entrepot(file:list):\n",
    "    '''Fonction qui effectue le traitement d'une liste de tweets provenant de la zone d'atterrissage. Le traitement consiste √† envoyer \n",
    "    les tweets dans une zone d'entrepot avec les informations essentielles'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 32\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m liste_tweet \u001b[39m=\u001b[39m openFile(\u001b[39m\"\u001b[39;49m\u001b[39mzone_atterrissage.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m zone_entreport_tweet \u001b[39m=\u001b[39m zoneEntrepot(liste_tweet)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m zone_entreport_tweet\n",
      "\u001b[1;32mc:\\L2 UVSQ 2022-2023\\IN 304\\TD\\ProjetIN304\\Projet.ipynb Cellule 32\u001b[0m in \u001b[0;36mopenFile\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m'''Fonction qui permet de lire et de recuperer un fichier json dans une variable data_dict'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fileName, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m json_data:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     data_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(json_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/L2%20UVSQ%202022-2023/IN%20304/TD/ProjetIN304/Projet.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data_dict\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\Camille Le Corre\\miniconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "liste_tweet = openFile(\"zone_atterrissage.json\")\n",
    "zone_entreport_tweet = zoneEntrepot(liste_tweet)\n",
    "zone_entreport_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoneEntrepot version Cam\n",
    "\n",
    "def ZoneEntrepot(list):\n",
    "    '''Fonction qui prend en entr√©e la liste des dictionnaires correspondant\n",
    "    aux tweets issus du fichier zone_atterrissage et qui cr√©er un DataFrame\n",
    "    contenant uniquement les informations qui nous int√©ressent'''\n",
    "\n",
    "    # Cr√©ation d'un DataFrame (chaque ligne va correspondre √† un tweet)\n",
    "    zone_entrepot = pd.DataFrame(columns = ['author_id', 'text', 'hashtags', 'mentioned_users', 'topics', 'feelings'])\n",
    "\n",
    "    for k in range(len(list)-1):        # on travaille sur un tweet √† la fois\n",
    "        # Cr√©ation d'une liste qui va contenir toutes les informations utiles de ce tweet\n",
    "        tweet = []\n",
    "        # Ajout √† cette liste des informations r√©cup√©r√©es de la zone d'atterissage\n",
    "        tweet.append(list[k].get(\"author_id\"))              # auteur du tweet    \n",
    "        tweet.append(list[k].get(\"text\"))                   # texte du tweet\n",
    "        tweet.append(listHashtags(list[k]))                 # liste des hashtags\n",
    "        tweet.append(listMentionedUsers(list[k]))           # liste des utilisateurs mentionn√©s\n",
    "        tweet.append(topic(list[k]))                        # topic\n",
    "        tweet.append(feeling(list[k]))                      # sentiment\n",
    "        \n",
    "        # Ajout de la ligne correspondant √† ce tweet √† notre DataFrame\n",
    "        zone_entrepot.loc[k+1] = tweet\n",
    "\n",
    "    return zone_entrepot    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II - Analyse des donn√©es\n",
    "\n",
    "Maintenant que nos tweets ont √©t√© nettoy√©s et que nous avons un DataFrame contenant uniquement les informations qui nous int√©ressent, nous allons pouvoir analyser et effectuer des statistiques sur nos tweets.\n",
    "\n",
    "Tout d'abord, nous cherchons √† obtenir les utilisateurs publiant le plus de tweets, les hashtags ou les mentions les plus utilis√©s, ou bien les topics les plus r√©pandus. Les fonctions suivantes vont permettre √† l'utilisateur de conna√Ætre le \"Top k\" parmis ces informations, o√π k est un nombre choisi par ce dernier.\n",
    "\n",
    "Les deux fonctions suivantes seront utilis√©es pour obtenir les tops k :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listColumn(df, column:str):\n",
    "    ''' Fonction qui renvoie les √©l√©ments d'une colonne d'un DataFrame sous forme d'une liste'''\n",
    "\n",
    "    type_elem = type(df[column][1])                     # on stocke le type des √©l√©ments de la colonne dans une variable\n",
    "\n",
    "    if type_elem == int or type_elem == str:            # si la colonne contient des entiers ou une cha√Æne de caract√®res\n",
    "        return list(df[column])\n",
    "    elif type_elem == list:                             # si la colonne contient des listes (une liste de hashatgs\n",
    "                                                        # ou d'utilisateurs mentionn√©s par exemple)\n",
    "        l_lists = list(df[column])\n",
    "        l_elem = []\n",
    "        for e in l_lists:\n",
    "            for ee in e:\n",
    "                l_elem.append(ee)\n",
    "        return l_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbOccurencesIntoDict(list_column):\n",
    "    ''' Fonction qui cr√©e un dictionnaire dans lequel chaque cl√© correspond √† un utilisateur\n",
    "    ou un hashtag etc, et chaque valeur correspond au nombre d'occurrences de cet √©l√©ment dans la liste'''\n",
    "\n",
    "    dic = {}\n",
    "\n",
    "    for elem in list_column:                # on parcourt la liste de tous les √©l√©ments d'une colonne\n",
    "        # Si on a d√©j√† rencontr√© cet √©l√©ment, on incr√©mente son nombre d'occurences de 1\n",
    "        if elem in dic:                     \n",
    "            dic[elem] += 1\n",
    "        # Si on ne l'a jamais rencontr√© encore, on ajoute une cl√©               \n",
    "        else:\n",
    "            dic[elem] = 1\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les quatres fonctions suivantes permettent de trier les hashtags, les utilisateurs, les utilisateurs mentionn√©s ou bien les topics, que l'on retrouve le plus de fois dans la colonne du DataFrame correspondante, √† celui qu'on retrouve le moins de fois.\n",
    "\n",
    "1. Pour les hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKHashtags(df, k):\n",
    "    ''' Fonction renvoyant les k hashtags les plus utilis√©s'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents hashtags\n",
    "    # et comme valeur le nombre de fois que chaque hashtag a √©t√© utilis√©\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, 'hashtags'))\n",
    "\n",
    "    # On trie le dictionnaire par ordre croissant des valeurs et on le transforme\n",
    "    # en liste pour renvoyer les k premiers hashtags les plus utilis√©s\n",
    "    return list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortHashtags(df):\n",
    "    ''' Fonction renvoyant une liste des hashtags tri√©s en fonction\n",
    "    du nombre de fois qu'ils ont √©t√© utilis√©s'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents hashtags\n",
    "    # et comme valeur le nombre de fois que chaque hashtag a √©t√© utilis√©\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, 'hashtags'))\n",
    "\n",
    "    # On trie le dictionnaire par ordre croissant des valeurs et on le transforme en liste\n",
    "    l = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pour les utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKUsers(df, k):\n",
    "    ''' Fonction renvoyant les k utilisateurs ayant publi√© le plus de tweets'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents utilisateurs et\n",
    "    # comme valeur le nombre de tweets qu'ils ont publi√©\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, \"author_id\"))\n",
    "\n",
    "    # On renvoie une liste des k utilisateurs ayant publi√© le plus de tweets\n",
    "    return list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortUsers(df):\n",
    "    ''' Fonction renvoyant une liste des utilisateurs tri√©s en fonction\n",
    "    du nombre de fois qu'ils ont publi√© un tweet'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents utilisateurs et\n",
    "    # comme valeur le nombre de tweets qu'ils ont publi√©\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, 'author_id'))\n",
    "\n",
    "    # On trie le dictionnaire par ordre croissant des valeurs et on le transforme en liste\n",
    "    l = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pour les utilisateurs mention√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKMentionedUsers(df, k):\n",
    "    ''' Fonction renvoyant les k utilisateurs les plus mentionn√©s'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents utilisateurs\n",
    "    # mentionn√©s et comme valeur le nombre de fois qu'ils ont √©t√© mention√©s\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, \"mentioned_users\"))\n",
    "\n",
    "    # On renvoie une liste des k utilisateurs mention√©s le plus de fois\n",
    "    return list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))[:k]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortMentionedUsers(df):\n",
    "    ''' Fonction renvoyant une liste des utilisateurs mentionn√©s\n",
    "    tri√©s en fonction du nombre de mentions'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents utilisateurs\n",
    "    # mentionn√©s et comme valeur le nombre de fois qu'ils ont √©t√© mention√©s\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, 'mentioned_users'))\n",
    "\n",
    "    # On trie le dictionnaire par ordre croissant des valeurs et on le transforme en liste\n",
    "    l = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pour les topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut g√©rer le cas quand les tweets n'ont pas de topic (None) -> dans liste colonne ? √† discuter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def topKTopics(df, k):\n",
    "    ''' Fonction renvoyant les k topics les plus r√©pandus'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents\n",
    "    # topics et comme valeur le nombre de tweets sur ce topic\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, \"topics\"))\n",
    "\n",
    "    # On renvoie une liste des k topics les plus r√©pandus\n",
    "    l_sorted = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))[:k]\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortTopics(df):\n",
    "    ''' Fonction renvoyant une liste des topics tri√©s en fonction\n",
    "    du nombre de fois qu'ils ont √©t√© utilis√©s'''\n",
    "\n",
    "    # On cr√©er un dictionnaire contenant comme cl√©s les diff√©rents\n",
    "    # topics et comme valeur le nombre de tweets sur ce topic\n",
    "    dic_occurences = nbOccurencesIntoDict(listColumn(df, 'topics'))\n",
    "\n",
    "    # On trie le dictionnaire par ordre croissant des valeurs et on le transforme en liste\n",
    "    l = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces quatre fonctions sont utilis√©es dans la fonction qui suit, permettant √† l'utilisateur de connaitre le Top k qu'il souhaite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topK(df):\n",
    "    ''' Fonction qui demande √† l'utilisateur le Top k qu'il souhaite connaitre,\n",
    "    ainsi que ce nombre k, puis qui renvoie ce classement demand√©'''\n",
    "\n",
    "    possible_top = ('H', 'U', 'UM', 'T')\n",
    "    top = 0\n",
    "    k = -1\n",
    "\n",
    "    # On demande √† l'utilisateur le Top qu'il souhaite connaitre\n",
    "    while top not in possible_top:\n",
    "        top = str(input(\"Quel Top voulez-vous connaitre ? hashtags (tapez H), utilisateurs (tapez U), utilisateurs mentionn√©s (tapez UM) ou bien topics (tapez T) ?\"))\n",
    "    \n",
    "    # Utilisation des fonctions de tri par ordre croissant des colonnes\n",
    "    # du DataFrame en fonction du choix de l'utilisateur\n",
    "    if top == 'H':\n",
    "        l = sortHashtags(df)\n",
    "    elif top == 'U':\n",
    "        l = sortUsers(df)\n",
    "    elif top == 'UM':\n",
    "        l = sortMentionedUsers(df)\n",
    "    else:\n",
    "        l = sortTopics(df)\n",
    "\n",
    "    # Nombre maximum que l'utilisateur pourra entrer pour la valeur de k\n",
    "    k_max = len(l)\n",
    "    \n",
    "    # Choix de la valeur k par l'utilisateur\n",
    "    while (k < 0) and (k > k_max):\n",
    "        k = int(input(\"Veuillez saisir k : \"))\n",
    "    \n",
    "    return l[:k]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester cette fonction et conna√Ætre le top k de votre choix, vous pouvez executer la cellule suivante et vous laisser guider par les instructions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topK(dic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb2b1035614daac4e449ec9b6a86cdf631e15e13424c7bda9ee941db7cd9c5ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
