{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TD 11 et 12 - Collecte, Traitement, et Analyse de donn√©es de r√©seaux sociaux**\n",
    "\n",
    "*LEFEVRE Laura et LE CORRE Camille - LDD BI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des modules\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "#Module a installer\n",
    "    #!pip install textblob\n",
    "    #!pip install textblob-fr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On d√©finit dans un premier temps, une fonction qui va nous permettre de r√©cup√©rer dans une variable, la liste des dictionnaires repr√©sentant les diff√©rents tweets contenu dans le fichier json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFile(fileName):\n",
    "    '''Fonction qui permet de lire et de recuperer un fichier json dans une variable data_dict'''\n",
    "    \n",
    "    with open(fileName, encoding='utf8') as json_data:\n",
    "        data_dict = json.load(json_data)\n",
    "        \n",
    "        return data_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, la commande suivante permet de r√©cup√©rer dans la varible dic, la liste des tweets du fichier \"versailles_tweets_100.json\". On obtient une liste de dictionnaire et dic[0] nous permet de visualiser le premier tweet. On peut voir qu'il poss√®de plusieurs √©l√©ments qui ne vont pas nous servir. Nous allons donc pouvoir nettoyer chacun des tweets, en gardant les informations essentiels (id, text, hastags...). De plus, on va pouvoir nettoyer le texte du tweet en supprimant tous les caract√®res sp√©ciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1421616335700824064',\n",
       " 'public_metrics': {'retweet_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 1,\n",
       "  'quote_count': 0},\n",
       " 'id': '1421616335700824064',\n",
       " 'conversation_id': '1421616335700824064',\n",
       " 'author_id': '1339914264522461187',\n",
       " 'text': 'Goumin des √©l√©phants joueurs la m√™me fatigue m√™me üò´ #twitter225',\n",
       " 'geo': {'place_id': '00b8943291443c8c'},\n",
       " 'lang': 'fr',\n",
       " 'created_at': '2021-07-31T23:38:41.000Z',\n",
       " 'entities': {'hashtags': [{'start': 52, 'end': 63, 'tag': 'twitter225'}]}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = openFile(\"versailles_tweets_100.json\")\n",
    "dic[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On code les fonctions permettant le nettoyage :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Supprimer les emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(data):\n",
    "    '''Fonction qui permet de supprimer les emojis du text d'un tweet \n",
    "    (source : https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python)'''\n",
    "    \n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Supprimer tous les caract√®res sp√©ciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanText(text):\n",
    "    '''Fonction qui permet de nettoyer le texte d'un tweet a l'aide de regex'''\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = remove_emojis(text)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', \"\", text)\n",
    "    text = re.sub(r'@([A-Za-z0-9_]+)', \"\", text)\n",
    "    text = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%¬∞\\.]*\", \"\", text)\n",
    "    text = re.sub(r\"#([A-Za-z0-9_]+)\", \"\", text)\n",
    "    text = re.sub(r\"[\\,\\!\\?\\%\\(\\)\\/\\\"\\&\\+\\#\\$\\¬£\\%\\:\\.\\@\\-\\n]\", \"\", text)\n",
    "    text = re.sub(r\"[\\√©\\√®\\√™]\", \"e\", text)\n",
    "    text = re.sub(r\"[\\√π]\", \"u\", text)\n",
    "    text = re.sub(r\"[\\√†]\", \"a\", text)\n",
    "    text = re.sub(r\"[\\√Æ\\√Ø]\", \"i\", text)\n",
    "    text = re.sub(r\"( )+\", \" \", text)\n",
    "    text = re.sub(r\"( )*$\", \"\", text)\n",
    "    text = re.sub(r\"^( )\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut maintenant cr√©er la zone d'atterrissage des tweets. \n",
    "On cr√©e donc une fonction qui va nous permettre d'ajouter les tweets dans un autre fichier json, semblable √† l'initial, mais avec des textes de tweet nettoy√©s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZoneAtterrissage(tweet):\n",
    "    '''Fonction qui permet de creer la zone d'atterrisage des tweets. Elle ajoute dans un fichier zone d'atterrissage, un tweet en le nettoyant.'''\n",
    "    \n",
    "    #Nettoie le texte du tweet et remplace le texte initiale par le texte nettoye\n",
    "    tweet_clean = CleanText(tweet['text'])\n",
    "    tweet['text'] = tweet_clean\n",
    "    \n",
    "    #Si le fichier de la zone d'atterrissage n'existe pas, on le creer et on y ajoute le tweet\n",
    "    if os.path.exists(\"zone_atterrissage.json\") == False:\n",
    "        with open(\"zone_atterrissage.json\", \"w\") as fil:\n",
    "            json.dump([tweet], fil)\n",
    "    \n",
    "    #Sinon, on recupere les tweets deja presents, et on y ajoute celui en cours de traitement\n",
    "    else :\n",
    "        li_tweet = openFile(\"zone_atterrissage.json\")\n",
    "        with open(\"zone_atterrissage.json\", 'w') as filout :\n",
    "            li_tweet.append(tweet)\n",
    "            json.dump(li_tweet, filout)\n",
    "            \n",
    "    return\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut maintenant une fonction qui va nous permettre de traiter les tweets que l'on a √† disposition. On va donc envoyer chaque tweet dans la zone d'atterrissage, l'un apr√®s l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_nettoyage(liste_tweet:list):\n",
    "    '''Cette fonction permet de traiter tous les tweets et de les envoyer dans la zone d'atterrissage'''\n",
    "\n",
    "    for elt in liste_tweet:\n",
    "        ZoneAtterrissage(elt)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On execute cette m√©thode en passant en param√®tre le fichier json contenant les tweets. Apr√®s l'ex√©cution on obtient un nouveau fichier json avec les tweets nettoy√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "traitement_nettoyage(dic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pr√©sent, tous les tweets sont stock√©s dans un nouveau fichier json. Ils sont nettoy√©s et on va pouvoir cr√©er une zone d'entrepot, sous forme de DataFrame. On va y stocker tous les tweets avec seulement les informations dont on a besoin.\n",
    "On va donc cr√©er un certain nombre de fonction qui vont nous permettre de r√©cup√©rer ces informations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Une fonction nous permettant d'extraire le texte d'un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract(tweet):\n",
    "    '''Fonction qui retourne le text d'un tweet'''\n",
    "\n",
    "    #On recupere le texte\n",
    "    text = tweet.get(\"text\")\n",
    "\n",
    "    #S'il n'y as pas de text (exemple : c'etait une mention), on retourne None\n",
    "    if text == '':\n",
    "        return\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Une fonction nous permettant d'extraire les Hashtags d'un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListHashtags(tweet):\n",
    "    ''' Fonction qui renvoie la liste de hashtags d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_hashtags = []\n",
    "    if \"entities\" in tweet:\n",
    "        if \"hashtags\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un hashtag\n",
    "            for h in range(len(tweet[\"entities\"][\"hashtags\"])):            # on parcourt la liste des hashtags\n",
    "                list_hashtags.append(tweet[\"entities\"][\"hashtags\"][h][\"tag\"])   \n",
    "            \n",
    "            return list_hashtags\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Une fonction nous permettant de r√©cup√©rer les utilisateurs mentionn√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListMentionedUsers(tweet):\n",
    "    ''' Fonction qui renvoie la liste des utilisateurs mentionn√©s dans un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "\n",
    "    list_mentioned_users = []\n",
    "    \n",
    "    if \"entities\" in tweet:\n",
    "        if \"mentions\" in tweet[\"entities\"]:                # on v√©rifie qu'il y a au moins un utilisateur mentionn√©\n",
    "            for m in range(len(tweet[\"entities\"][\"mentions\"])):            # on parcourt la liste des utilisateurs mentionn√©s\n",
    "                list_mentioned_users.append(tweet[\"entities\"][\"mentions\"][m][\"username\"])\n",
    "            \n",
    "            return list_mentioned_users\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Une fonction nous permettant d'attribuer un topic √† un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topic(tweet):\n",
    "    ''' Fonction qui d√©termine le topic d'un tweet.\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Une fonction nous permettant d'attribuer un sentiment au tweet en fonction du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feeling(tweet):\n",
    "    ''' Fonction qui d√©termine le sentiment d'un tweet (positif, n√©gatif ou neutre).\n",
    "    Cette fonction est utilis√©e dans la fonction ZoneEntrepot '''\n",
    "    \n",
    "    feeling = TextBlob(tweet.get(\"text\")).sentiment\n",
    "    \n",
    "    if feeling[0] < 0:\n",
    "        return \"negative\"\n",
    "    elif feeling[0] == 0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apr√®s avoir d√©clar√© toutes ces fonctions, on peut cr√©er une fonction zone entrepot pour cr√©er un DataFrame contenant les tweets avec les informations des fonctions pr√©c√©dentes. Chaque tweet va correspondre √† une ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoneEntrepot(list):\n",
    "    '''Fonction qui prend en entr√©e la liste des dictionnaires correspondant\n",
    "    aux tweets issus du fichier zone_atterrissage.json et qui cr√©er un DataFrame\n",
    "    contenant uniquement les informations qui nous int√©ressent'''\n",
    "\n",
    "    # Cr√©ation d'un DataFrame\n",
    "    zone_entrepot = pd.DataFrame(columns = ['author_id', 'text', 'hashtags', 'mentioned_users', 'topics', 'feelings'])\n",
    "\n",
    "    for k in range(len(list)):        # on travaille sur un tweet √† la fois\n",
    "        # Cr√©ation d'une liste qui va contenir toutes les informations utiles de ce tweet\n",
    "        tweet = []\n",
    "        \n",
    "        # Ajout √† cette liste des informations r√©cup√©r√©es de la zone d'atterissage\n",
    "        tweet.extend([list[k].get(\"author_id\"), text_extract(list[k]), ListHashtags(list[k]), ListMentionedUsers(list[k]),Topic(list[k]), Feeling(list[k])])  \n",
    "        \n",
    "        # Ajout de la ligne correspondant au tweet, √† notre DataFrame\n",
    "        zone_entrepot.loc[k+1] = tweet\n",
    "\n",
    "    return zone_entrepot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traitement_entrepot(file:list):\n",
    "    '''Fonction qui effectue le traitement d'une liste de tweets provenant de la zone d'atterrissage. Le traitement consiste √† envoyer \n",
    "    les tweets dans une zone d'entrepot avec les informations essentielles'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentioned_users</th>\n",
       "      <th>topics</th>\n",
       "      <th>feelings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>goumin des elephants joueurs la meme fatigue meme</td>\n",
       "      <td>[twitter225]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>mes tontons vous avez fait votre part jo proch...</td>\n",
       "      <td>[SupportriceMazo, domie, CIV]</td>\n",
       "      <td>[ericbailly24, maxigr04del]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>ah oui le sommeil la sera complique est elimin...</td>\n",
       "      <td>[CIV]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339914264522461187</td>\n",
       "      <td>juillet journee internationale de la femme afr...</td>\n",
       "      <td>[jifa]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>717025418</td>\n",
       "      <td>le pedigree</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>vous avez tt a fait raison le silence incompre...</td>\n",
       "      <td>None</td>\n",
       "      <td>[isabelle170516, leonna_julie, Steiner2502]</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>la grande muette continue et continuera de le ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[LynLyna12, leonna_julie]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>736523371</td>\n",
       "      <td>under wsh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1471684208</td>\n",
       "      <td>les bains d'apollon a ch√¢teau de versailles</td>\n",
       "      <td>[versailles, nocturne, appollon]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>le rdv aujourd'hui aura tenu ses promesses pou...</td>\n",
       "      <td>None</td>\n",
       "      <td>[leonna_julie]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>il est temps de laisser mijoter</td>\n",
       "      <td>None</td>\n",
       "      <td>[miliemelo82, kilianbridoux, LeMeneec]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>992904738516717570</td>\n",
       "      <td>un mouton c'est bien plus intelligent que toi</td>\n",
       "      <td>None</td>\n",
       "      <td>[Polo82810715, lrestistant73]</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16267684</td>\n",
       "      <td>i'm at gardens of versailles in versailles ile...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60117154</td>\n",
       "      <td>jungle cruise</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3169236915</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[Pauluskupa]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>372993152</td>\n",
       "      <td>legend</td>\n",
       "      <td>None</td>\n",
       "      <td>[anniemacmanus]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>372993152</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[yebbasmith, anniemacmanus]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>105241852</td>\n",
       "      <td>vient de publier une photo a quelquepart</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2357913366</td>\n",
       "      <td>he was my lover‚Äôs accomplice</td>\n",
       "      <td>None</td>\n",
       "      <td>[AzmiAnees3]</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>717025418</td>\n",
       "      <td>le gardien lui parle non</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author_id                                               text  \\\n",
       "1   1339914264522461187  goumin des elephants joueurs la meme fatigue meme   \n",
       "2   1339914264522461187  mes tontons vous avez fait votre part jo proch...   \n",
       "3   1339914264522461187  ah oui le sommeil la sera complique est elimin...   \n",
       "4   1339914264522461187  juillet journee internationale de la femme afr...   \n",
       "5             717025418                                        le pedigree   \n",
       "6    992904738516717570  vous avez tt a fait raison le silence incompre...   \n",
       "7    992904738516717570  la grande muette continue et continuera de le ...   \n",
       "8             736523371                                          under wsh   \n",
       "9            1471684208        les bains d'apollon a ch√¢teau de versailles   \n",
       "10   992904738516717570  le rdv aujourd'hui aura tenu ses promesses pou...   \n",
       "11           3169236915                    il est temps de laisser mijoter   \n",
       "12   992904738516717570      un mouton c'est bien plus intelligent que toi   \n",
       "13             16267684  i'm at gardens of versailles in versailles ile...   \n",
       "14             60117154                                      jungle cruise   \n",
       "15           3169236915                                               None   \n",
       "16            372993152                                             legend   \n",
       "17            372993152                                               None   \n",
       "18            105241852           vient de publier une photo a quelquepart   \n",
       "19           2357913366                       he was my lover‚Äôs accomplice   \n",
       "20            717025418                           le gardien lui parle non   \n",
       "\n",
       "                            hashtags  \\\n",
       "1                       [twitter225]   \n",
       "2      [SupportriceMazo, domie, CIV]   \n",
       "3                              [CIV]   \n",
       "4                             [jifa]   \n",
       "5                               None   \n",
       "6                               None   \n",
       "7                               None   \n",
       "8                               None   \n",
       "9   [versailles, nocturne, appollon]   \n",
       "10                              None   \n",
       "11                              None   \n",
       "12                              None   \n",
       "13                              None   \n",
       "14                              None   \n",
       "15                              None   \n",
       "16                              None   \n",
       "17                              None   \n",
       "18                              None   \n",
       "19                              None   \n",
       "20                              None   \n",
       "\n",
       "                                mentioned_users topics  feelings  \n",
       "1                                          None   None   neutral  \n",
       "2                   [ericbailly24, maxigr04del]   None   neutral  \n",
       "3                                          None   None   neutral  \n",
       "4                                          None   None   neutral  \n",
       "5                                          None   None   neutral  \n",
       "6   [isabelle170516, leonna_julie, Steiner2502]   None  positive  \n",
       "7                     [LynLyna12, leonna_julie]   None   neutral  \n",
       "8                                          None   None   neutral  \n",
       "9                                          None   None   neutral  \n",
       "10                               [leonna_julie]   None   neutral  \n",
       "11       [miliemelo82, kilianbridoux, LeMeneec]   None   neutral  \n",
       "12                [Polo82810715, lrestistant73]   None  positive  \n",
       "13                                         None   None   neutral  \n",
       "14                                         None   None   neutral  \n",
       "15                                 [Pauluskupa]   None   neutral  \n",
       "16                              [anniemacmanus]   None   neutral  \n",
       "17                  [yebbasmith, anniemacmanus]   None   neutral  \n",
       "18                                         None   None   neutral  \n",
       "19                                 [AzmiAnees3]   None   neutral  \n",
       "20                                         None   None   neutral  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_tweet = openFile(\"zone_atterrissage.json\")\n",
    "zone_entreport_tweet = zoneEntrepot(liste_tweet)\n",
    "zone_entreport_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZoneEntrepot(list):\n",
    "    '''Fonction qui prend en entr√©e la liste des dictionnaires correspondant\n",
    "    aux tweets issus du fichier zone_atterrissage et qui cr√©er un DataFrame\n",
    "    contenant uniquement les informations qui nous int√©ressent'''\n",
    "\n",
    "    # Cr√©ation d'un DataFrame (chaque ligne va correspondre √† un tweet)\n",
    "    zone_entrepot = pd.DataFrame(columns = ['author_id', 'text', 'hashtags', 'mentioned_users', 'topics', 'feelings'])\n",
    "\n",
    "    for k in range(len(list)-1):        # on travaille sur un tweet √† la fois\n",
    "        # Cr√©ation d'une liste qui va contenir toutes les informations utiles de ce tweet\n",
    "        tweet = []\n",
    "        # Ajout √† cette liste des informations r√©cup√©r√©es de la zone d'atterissage\n",
    "        tweet.append(list[k].get(\"author_id\"))              # auteur du tweet    \n",
    "        tweet.append(list[k].get(\"text\"))                   # texte du tweet\n",
    "        tweet.append(ListHashtags(list[k]))                 # liste des hashtags\n",
    "        tweet.append(ListMentionedUsers(list[k]))           # liste des utilisateurs mentionn√©s\n",
    "        tweet.append(Topic(list[k]))                        # topic\n",
    "        tweet.append(Feeling(list[k]))                      # sentiment\n",
    "        \n",
    "        # Ajout de la ligne correspondant √† ce tweet √† notre DataFrame\n",
    "        zone_entrepot.loc[k+1] = tweet\n",
    "\n",
    "    return zone_entrepot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListColumn(df, column:str):\n",
    "    ''' Fonction qui renvoie les √©l√©ments d'une colonne d'un DataFrame sous forme d'une liste'''\n",
    "\n",
    "    return list(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NbOccurencesIntoDict(l):\n",
    "    ''' Fonction qui cr√©e un dictionnaire dans lequel chaque cl√©\n",
    "    correspond √† un utilisateur, et chaque valeur correspond au nombre\n",
    "    d'occurrences de cet utilisateur dans la liste'''\n",
    "\n",
    "    dic = {}\n",
    "\n",
    "    for elem in l:\n",
    "        if elem in dic:\n",
    "            dic[elem] += 1\n",
    "        else:\n",
    "            dic[elem] = 1\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopKUsers(df, k):\n",
    "    ''' Fonction renvoyant les k utilisateurs ayant publi√© le plus de tweets'''\n",
    "\n",
    "    l_users = ListColumn(df, \"author_id\")\n",
    "    dic_occurences = NbOccurencesIntoDict(l_users)\n",
    "    #dic_occurences = NbOccurencesIntoDict(ListColumn(df, \"author_id\"))\n",
    "\n",
    "    l_sorted = list(sorted(dic_occurences, key=dic_occurences.get, reverse=True))\n",
    "\n",
    "    return l_sorted[:k]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('l1-python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fffb65c47ed2133fd664d3a0067ed67d5fc57a12224b3043734fa1ac4f51c235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
